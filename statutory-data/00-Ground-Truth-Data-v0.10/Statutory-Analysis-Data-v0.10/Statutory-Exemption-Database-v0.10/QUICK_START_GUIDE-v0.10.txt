================================================================================
STATUTORY EXEMPTION DATABASE - QUICK START GUIDE
================================================================================

WHAT WAS CREATED
================================================================================

This extraction created comprehensive datasets of requestor rights and 
statutory exemptions from transparency laws across all 51 U.S. jurisdictions
(50 states + DC + Federal FOIA).

Total Output: 186 files containing 1,497 records
  - 182 jurisdiction-specific files (CSV + JSON)
  - 4 master dataset files (CSV + JSON)

================================================================================
FILE STRUCTURE
================================================================================

Output-Data/
├── By-State/                    # Individual jurisdiction files
│   ├── Alabama_requestor_rights.csv
│   ├── Alabama_requestor_rights.json
│   ├── Alabama_exemptions.csv
│   ├── Alabama_exemptions.json
│   ├── ... (all 51 jurisdictions)
│   └── Wyoming_exemptions.json
│
└── Master-Datasets/             # Combined data for all jurisdictions
    ├── ALL_JURISDICTIONS_requestor_rights.csv
    ├── ALL_JURISDICTIONS_requestor_rights.json
    ├── ALL_JURISDICTIONS_exemptions.csv
    └── ALL_JURISDICTIONS_exemptions.json

================================================================================
HOW TO USE THE DATA
================================================================================

1. FOR SINGLE JURISDICTION ANALYSIS:
   
   Use the By-State files:
   - Wyoming_requestor_rights.csv → Import into Excel/Notion/Supabase
   - Wyoming_exemptions.json → Use for AI training or app development

2. FOR COMPARATIVE ANALYSIS:
   
   Use the Master-Datasets files:
   - ALL_JURISDICTIONS_requestor_rights.csv → Compare across states
   - Filter by jurisdiction_code to analyze specific states
   - Sort by category to see patterns

3. FOR AI/ML TRAINING:
   
   Use the JSON files:
   - Structured metadata for model training
   - Records grouped by category
   - All context preserved in nested structure

4. FOR DATABASE IMPORT:
   
   Use the CSV files:
   - Standard 11-column structure
   - Compatible with Notion, Supabase, Airtable, PostgreSQL
   - Normalized jurisdiction codes for joining

================================================================================
KEY DATA FIELDS
================================================================================

jurisdiction_name  → Full name (e.g., "Federal", "Wyoming")
jurisdiction_code  → ISO-style code (e.g., "US-FED", "US-WY")
law_name          → Name of transparency law
statute_citation  → Primary statute reference
section_reference → Specific sections/clauses
category          → Main category (Response Timeline, Exemption, etc.)
subcategory       → Specific type or provision
description       → Detailed description
conditions        → Limitations or requirements
notes             → Source and context
extraction_date   → ISO 8601 timestamp

================================================================================
COMMON QUERIES
================================================================================

Q: How many exemptions does Federal FOIA have?
A: Open Federal_exemptions.csv → Count = 9 (b)(1) through (b)(9)

Q: What are Wyoming's response timelines?
A: Open Wyoming_requestor_rights.csv → Filter category="Response Timeline"

Q: Which states have the most exemptions?
A: Open ALL_JURISDICTIONS_exemptions.csv → Count by jurisdiction_name

Q: What fee structures exist across states?
A: Open ALL_JURISDICTIONS_requestor_rights.csv → Filter category="Fee Structure"

Q: Which exemptions are most common?
A: Open ALL_JURISDICTIONS_exemptions.csv → Group by subcategory

================================================================================
SAMPLE PYTHON USAGE
================================================================================

# Load requestor rights for analysis
import pandas as pd
df = pd.read_csv('Output-Data/Master-Datasets/ALL_JURISDICTIONS_requestor_rights.csv')

# Filter to Wyoming only
wyoming = df[df['jurisdiction_code'] == 'US-WY']

# Get all response timelines across states
timelines = df[df['category'] == 'Response Timeline']

# Count records by state
by_state = df.groupby('jurisdiction_name').size()

# Load JSON for structured analysis
import json
with open('Output-Data/Master-Datasets/ALL_JURISDICTIONS_exemptions.json') as f:
    exemptions = json.load(f)
    
print(f"Total exemptions: {exemptions['metadata']['total_records']}")
federal = [r for r in exemptions['records'] if r['jurisdiction_code'] == 'US-FED']

================================================================================
SAMPLE SQL QUERIES (After DB Import)
================================================================================

-- Count requestor rights by jurisdiction
SELECT jurisdiction_name, COUNT(*) as total_rights
FROM requestor_rights
GROUP BY jurisdiction_name
ORDER BY total_rights DESC;

-- Find all law enforcement exemptions
SELECT jurisdiction_name, description
FROM exemptions
WHERE subcategory LIKE '%Law Enforcement%';

-- Compare response timelines
SELECT jurisdiction_name, description
FROM requestor_rights
WHERE category = 'Response Timeline'
ORDER BY jurisdiction_name;

-- Get Federal FOIA exemptions
SELECT section_reference, description
FROM exemptions
WHERE jurisdiction_code = 'US-FED'
ORDER BY section_reference;

================================================================================
INTEGRATION EXAMPLES
================================================================================

NOTION:
1. Create database
2. Import ALL_JURISDICTIONS_requestor_rights.csv
3. Set jurisdiction_code as relation field
4. Create views: By State, By Category, Timeline Analysis

SUPABASE:
1. Create table: requestor_rights
2. Import CSV via dashboard or SQL
3. Add RLS policies as needed
4. Create views for common queries

AIRTABLE:
1. Create base
2. Import CSV to table
3. Create linked records for jurisdictions
4. Build interfaces for searching

EXCEL/GOOGLE SHEETS:
1. Import CSV
2. Create pivot tables
3. Use filters for analysis
4. Build dashboards with charts

================================================================================
TIPS FOR SUCCESS
================================================================================

✓ Use jurisdiction_code for consistent filtering (handles multi-word states)
✓ Category field is pre-categorized for easy analysis
✓ Description field contains the most detailed information
✓ Conditions field shows limitations and requirements
✓ JSON files include metadata useful for provenance tracking

✓ Some formatting artifacts exist (leading colons) - easy to clean
✓ Statute citations mostly show "Citation not found" but section_reference
  field contains the actual references extracted from documents
✓ Exemption counts vary by state based on source document structure

✓ Federal FOIA data is most comprehensive (serves as gold standard)
✓ State data quality reflects variety in source document formats
✓ All data comes from VERIFIED Process Maps (Sept 2025)

================================================================================
SUPPORT FILES
================================================================================

extract_statutory_data.py  → The extraction script (can be re-run)
EXTRACTION_SUMMARY.txt     → Detailed technical report
QUICK_START_GUIDE.txt      → This file
readme.md                  → Project overview

================================================================================
RE-RUNNING THE EXTRACTION
================================================================================

To re-extract or process updated source files:

python3 extract_statutory_data.py

The script will:
1. Parse all 51 VERIFIED-Process-Map.md files
2. Extract requestor rights and exemptions
3. Generate CSV and JSON outputs
4. Create by-state and master datasets
5. Report statistics and any errors

Typical run time: 30-60 seconds

================================================================================
QUESTIONS OR ISSUES?
================================================================================

Check EXTRACTION_SUMMARY.txt for detailed technical information about:
- Data structure and schemas
- Extraction methodology
- Known limitations
- Recommended enhancements

The extraction script includes comprehensive comments and can be modified
for specific needs or to enhance extraction patterns.

================================================================================
END OF QUICK START GUIDE
================================================================================
